{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EuEex0sF-9C",
        "outputId": "ad07b75e-695d-4263-8894-3bb0cc0ea02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1/100 completed.\n",
            "Generation 2/100 completed.\n",
            "Generation 3/100 completed.\n",
            "Generation 4/100 completed.\n",
            "Generation 5/100 completed.\n",
            "Generation 6/100 completed.\n",
            "Generation 7/100 completed.\n",
            "Generation 8/100 completed.\n",
            "Generation 9/100 completed.\n",
            "Generation 10/100 completed.\n",
            "Generation 11/100 completed.\n",
            "Generation 12/100 completed.\n",
            "Generation 13/100 completed.\n",
            "Generation 14/100 completed.\n",
            "Generation 15/100 completed.\n",
            "Generation 16/100 completed.\n",
            "Generation 17/100 completed.\n",
            "Generation 18/100 completed.\n",
            "Generation 19/100 completed.\n",
            "Generation 20/100 completed.\n",
            "Generation 21/100 completed.\n",
            "Generation 22/100 completed.\n",
            "Generation 23/100 completed.\n",
            "Generation 24/100 completed.\n",
            "Generation 25/100 completed.\n",
            "Generation 26/100 completed.\n",
            "Generation 27/100 completed.\n",
            "Generation 28/100 completed.\n",
            "Generation 29/100 completed.\n",
            "Generation 30/100 completed.\n",
            "Generation 31/100 completed.\n",
            "Generation 32/100 completed.\n",
            "Generation 33/100 completed.\n",
            "Generation 34/100 completed.\n",
            "Generation 35/100 completed.\n",
            "Generation 36/100 completed.\n",
            "Generation 37/100 completed.\n",
            "Generation 38/100 completed.\n",
            "Generation 39/100 completed.\n",
            "Generation 40/100 completed.\n",
            "Generation 41/100 completed.\n",
            "Generation 42/100 completed.\n",
            "Generation 43/100 completed.\n",
            "Generation 44/100 completed.\n",
            "Generation 45/100 completed.\n",
            "Generation 46/100 completed.\n",
            "Generation 47/100 completed.\n",
            "Generation 48/100 completed.\n",
            "Generation 49/100 completed.\n",
            "Generation 50/100 completed.\n",
            "Generation 51/100 completed.\n",
            "Generation 52/100 completed.\n",
            "Generation 53/100 completed.\n",
            "Generation 54/100 completed.\n",
            "Generation 55/100 completed.\n",
            "Generation 56/100 completed.\n",
            "Generation 57/100 completed.\n",
            "Generation 58/100 completed.\n",
            "Generation 59/100 completed.\n",
            "Generation 60/100 completed.\n",
            "Generation 61/100 completed.\n",
            "Generation 62/100 completed.\n",
            "Generation 63/100 completed.\n",
            "Generation 64/100 completed.\n",
            "Generation 65/100 completed.\n",
            "Generation 66/100 completed.\n",
            "Generation 67/100 completed.\n",
            "Generation 68/100 completed.\n",
            "Generation 69/100 completed.\n",
            "Generation 70/100 completed.\n",
            "Generation 71/100 completed.\n",
            "Generation 72/100 completed.\n",
            "Generation 73/100 completed.\n",
            "Generation 74/100 completed.\n",
            "Generation 75/100 completed.\n",
            "Generation 76/100 completed.\n",
            "Generation 77/100 completed.\n",
            "Generation 78/100 completed.\n",
            "Generation 79/100 completed.\n",
            "Generation 80/100 completed.\n",
            "Generation 81/100 completed.\n",
            "Generation 82/100 completed.\n",
            "Generation 83/100 completed.\n",
            "Generation 84/100 completed.\n",
            "Generation 85/100 completed.\n",
            "Generation 86/100 completed.\n",
            "Generation 87/100 completed.\n",
            "Generation 88/100 completed.\n",
            "Generation 89/100 completed.\n",
            "Generation 90/100 completed.\n",
            "Generation 91/100 completed.\n",
            "Generation 92/100 completed.\n",
            "Generation 93/100 completed.\n",
            "Generation 94/100 completed.\n",
            "Generation 95/100 completed.\n",
            "Generation 96/100 completed.\n",
            "Generation 97/100 completed.\n",
            "Generation 98/100 completed.\n",
            "Generation 99/100 completed.\n",
            "Generation 100/100 completed.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define your optimization problem and objectives here\n",
        "\n",
        "# Initialization\n",
        "def initialize_population(pop_size, num_variables):\n",
        "    return np.random.rand(pop_size, num_variables)  # Randomly initialize population\n",
        "\n",
        "def evaluate_objectives(population):\n",
        "    # Evaluate the population with respect to all objectives\n",
        "    # Replace this with your objective functions\n",
        "    objective1 = np.sum(population, axis=1)  # Example objective 1\n",
        "    objective2 = np.sum((population - 2) ** 2, axis=1)  # Example objective 2\n",
        "    return np.column_stack((objective1, objective2))\n",
        "\n",
        "# Differential Evolution Operators\n",
        "def mutation(population, F):\n",
        "    # Mutation operator\n",
        "    donor_vectors = population[np.random.choice(pop_size, pop_size, replace=False)]\n",
        "    return population + F * (donor_vectors - population)\n",
        "\n",
        "def crossover(target_vectors, trial_vectors, CR):\n",
        "    # Crossover operator\n",
        "    mask = np.random.rand(pop_size, num_variables) < CR\n",
        "    return np.where(mask, trial_vectors, target_vectors)\n",
        "\n",
        "# Multi-Objective Differential Evolution\n",
        "def multi_objective_differential_evolution(pop_size, num_variables, max_generations, F, CR):\n",
        "    population = initialize_population(pop_size, num_variables)\n",
        "    objectives = evaluate_objectives(population)\n",
        "\n",
        "    for generation in range(max_generations):\n",
        "        trial_population = mutation(population, F)\n",
        "        trial_population = np.clip(trial_population, 0, 1)  # Ensure solutions are within bounds\n",
        "        trial_objectives = evaluate_objectives(trial_population)\n",
        "\n",
        "        # Survival selection (Non-dominated sorting and crowding distance)\n",
        "        combined_population = np.vstack((population, trial_population))\n",
        "        combined_objectives = np.vstack((objectives, trial_objectives))\n",
        "\n",
        "        # Implement non-dominated sorting and crowding distance here\n",
        "\n",
        "        # Select the top pop_size solutions based on non-dominated sorting and crowding distance\n",
        "\n",
        "        # Update population and objectives\n",
        "\n",
        "        print(f\"Generation {generation + 1}/{max_generations} completed.\")\n",
        "\n",
        "    return population, objectives\n",
        "\n",
        "# Example usage\n",
        "pop_size = 100\n",
        "num_variables = 5\n",
        "max_generations = 100\n",
        "F = 0.5  # Mutation scaling factor\n",
        "CR = 0.7  # Crossover probability\n",
        "\n",
        "final_population, final_objectives = multi_objective_differential_evolution(pop_size, num_variables, max_generations, F, CR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyyeT6DwHxqh",
        "outputId": "808fc0ff-715d-407a-d8fd-9b5f416841af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8.08268861e-01 5.46072949e-01 3.60953581e-02 1.03034454e-01\n",
            "  1.26004580e-01]\n",
            " [3.60166083e-01 2.27417717e-01 4.45456116e-01 8.46953562e-01\n",
            "  1.20302610e-01]\n",
            " [8.21992652e-01 4.99224352e-01 5.05960811e-01 9.69938889e-02\n",
            "  1.98335922e-01]\n",
            " [8.21371852e-01 1.02529577e-01 9.39969415e-01 6.07536845e-02\n",
            "  5.82405976e-01]\n",
            " [9.48626329e-01 6.19704694e-01 6.92915191e-01 9.63659880e-01\n",
            "  3.20025236e-01]\n",
            " [6.11933504e-01 1.18609598e-02 4.52270219e-01 4.27027533e-01\n",
            "  7.30041586e-01]\n",
            " [3.24484970e-01 2.45023589e-01 3.55862710e-01 1.73692812e-01\n",
            "  7.36602917e-01]\n",
            " [5.20543287e-01 2.36233766e-01 7.82389476e-01 2.91821494e-01\n",
            "  6.85700484e-01]\n",
            " [9.27386131e-01 4.52059512e-01 3.55266561e-01 5.04209742e-01\n",
            "  7.93462219e-01]\n",
            " [5.00529040e-01 2.81666711e-01 7.41754451e-01 2.31563581e-01\n",
            "  8.29422829e-01]\n",
            " [8.03376528e-01 6.94430276e-01 8.45061207e-01 5.34623331e-03\n",
            "  1.54697111e-01]\n",
            " [1.99846800e-01 6.59262810e-01 4.54859125e-01 7.16917159e-02\n",
            "  7.35983397e-01]\n",
            " [5.92360368e-02 5.45421442e-01 9.78913282e-01 3.69613207e-01\n",
            "  4.54257161e-01]\n",
            " [7.11792869e-01 7.74401912e-01 2.88848561e-01 1.71207206e-02\n",
            "  5.57157259e-01]\n",
            " [2.14398805e-02 5.35897647e-01 4.87182437e-01 6.47742879e-02\n",
            "  5.68989186e-01]\n",
            " [5.86872988e-01 6.34788886e-01 1.50595102e-01 6.18252152e-01\n",
            "  4.48123199e-01]\n",
            " [5.42263880e-01 2.49815024e-01 1.77034340e-01 6.10655138e-01\n",
            "  1.75281347e-01]\n",
            " [3.05002885e-01 9.29859196e-01 4.75718884e-01 3.03632314e-01\n",
            "  5.73571600e-02]\n",
            " [6.34467317e-01 5.02463098e-01 2.80042818e-01 5.48611768e-01\n",
            "  6.66701141e-01]\n",
            " [2.52083719e-02 5.00897512e-02 5.44799956e-01 9.07324870e-01\n",
            "  7.47880177e-01]\n",
            " [3.99243186e-01 5.45737133e-01 9.97432340e-01 4.80855208e-01\n",
            "  4.89572468e-01]\n",
            " [7.01543890e-01 9.89222822e-01 6.13541226e-01 2.96269124e-01\n",
            "  1.25381880e-01]\n",
            " [7.87316000e-01 7.06999671e-01 6.68673089e-01 3.76806843e-01\n",
            "  5.76523569e-01]\n",
            " [3.39698208e-01 6.09542767e-01 3.09762097e-01 7.30142712e-01\n",
            "  8.67200098e-01]\n",
            " [5.75719538e-01 7.69768417e-02 8.39429578e-01 7.61381451e-01\n",
            "  3.63024673e-01]\n",
            " [5.81113971e-01 4.60485983e-02 7.52012774e-01 5.33409574e-01\n",
            "  6.59820355e-01]\n",
            " [5.44777809e-01 5.16945181e-01 1.43786121e-01 1.50553846e-01\n",
            "  7.29834424e-01]\n",
            " [9.28914631e-01 1.72377415e-01 7.34238836e-02 5.52347802e-01\n",
            "  5.65952646e-01]\n",
            " [4.44230612e-01 9.60470432e-01 5.63750937e-01 3.13441849e-01\n",
            "  1.60229817e-01]\n",
            " [4.18830527e-01 9.37666079e-01 5.55485685e-01 3.84524659e-01\n",
            "  9.85950773e-01]\n",
            " [7.59023418e-01 4.58745234e-01 3.70296855e-01 1.28029806e-01\n",
            "  9.94785020e-01]\n",
            " [5.01157532e-01 7.62295082e-01 2.76654737e-01 5.32572103e-01\n",
            "  1.48227863e-01]\n",
            " [1.36934748e-01 4.41622425e-01 3.57426964e-03 6.63679227e-01\n",
            "  3.08148859e-01]\n",
            " [7.83914037e-01 2.63890356e-01 9.28114962e-01 8.82256339e-01\n",
            "  6.46552861e-01]\n",
            " [4.25732712e-01 4.76117140e-01 3.38941305e-01 1.63130968e-01\n",
            "  1.81120717e-01]\n",
            " [3.55518248e-01 7.16090255e-01 4.45329074e-01 2.36953607e-01\n",
            "  6.03450560e-01]\n",
            " [8.41006331e-01 2.75576894e-01 9.68721863e-02 6.42575764e-01\n",
            "  8.90047894e-02]\n",
            " [3.43757793e-02 1.01874673e-01 2.60330893e-01 1.57064655e-01\n",
            "  5.26429197e-01]\n",
            " [4.11295643e-01 2.57446848e-01 8.65544738e-01 4.52207271e-01\n",
            "  7.55580415e-01]\n",
            " [8.62084370e-01 3.38874104e-01 6.13886320e-01 1.04886241e-01\n",
            "  8.95913368e-01]\n",
            " [9.12047881e-01 4.57595440e-01 9.68649733e-01 8.01885461e-01\n",
            "  7.75788496e-01]\n",
            " [9.60552102e-01 5.11710225e-01 9.22256916e-02 8.82699016e-01\n",
            "  8.65193254e-01]\n",
            " [9.36456091e-01 5.95030560e-01 8.82135376e-01 5.18197008e-01\n",
            "  1.78418587e-01]\n",
            " [3.22088169e-01 6.41176497e-01 6.93459795e-01 3.49352040e-01\n",
            "  2.95701807e-01]\n",
            " [3.21568498e-01 3.93314803e-01 4.18901237e-01 7.81466550e-01\n",
            "  5.31519906e-01]\n",
            " [4.58708371e-01 7.04900694e-01 8.90654922e-01 7.48719651e-01\n",
            "  3.54035287e-01]\n",
            " [5.86090661e-01 7.96784600e-01 9.73736207e-01 1.58829923e-01\n",
            "  6.61441939e-01]\n",
            " [4.09790638e-01 9.54796771e-01 9.49328394e-01 4.03534149e-01\n",
            "  9.43596620e-02]\n",
            " [2.30385736e-02 7.90276062e-01 8.45101058e-01 1.11251969e-02\n",
            "  6.10692117e-01]\n",
            " [2.88975021e-01 6.96093291e-01 4.18145776e-03 1.78763679e-01\n",
            "  7.02098225e-01]\n",
            " [4.58589022e-01 7.81007471e-01 1.76532207e-01 2.16872784e-01\n",
            "  6.53309523e-01]\n",
            " [8.82685245e-01 2.39635814e-01 1.36687615e-01 4.78372230e-01\n",
            "  7.97598867e-01]\n",
            " [9.99042708e-01 7.10717170e-01 9.99996268e-01 9.34006871e-02\n",
            "  8.78825456e-01]\n",
            " [9.05918909e-02 5.19400551e-02 2.72312296e-02 5.94702823e-02\n",
            "  6.82131574e-01]\n",
            " [1.64128586e-01 2.51367871e-01 9.50344751e-01 5.38441292e-01\n",
            "  5.66307917e-01]\n",
            " [2.67710946e-01 3.57000082e-01 8.46986567e-01 4.47441000e-01\n",
            "  3.30837819e-01]\n",
            " [7.96761094e-01 8.36227858e-01 6.39409846e-01 4.88555203e-01\n",
            "  9.61154731e-01]\n",
            " [7.40275416e-01 4.69512512e-01 7.25676628e-01 1.71299111e-01\n",
            "  8.52337727e-01]\n",
            " [6.06614555e-01 5.70746921e-01 6.06974286e-01 7.91554599e-01\n",
            "  9.47602634e-01]\n",
            " [5.12271676e-01 4.11798373e-01 1.38503402e-01 5.14889426e-01\n",
            "  4.11072534e-01]\n",
            " [8.99561065e-01 4.71478429e-01 6.14730851e-01 1.95487786e-01\n",
            "  2.61610685e-01]\n",
            " [8.60216502e-01 2.76889827e-02 9.86008585e-01 5.53420065e-01\n",
            "  2.75705424e-01]\n",
            " [1.73481300e-02 7.39345245e-01 7.04461079e-01 9.69436046e-01\n",
            "  5.06316373e-01]\n",
            " [1.88817759e-01 7.97117472e-01 3.18629589e-01 5.03697499e-01\n",
            "  4.30300162e-01]\n",
            " [7.82160716e-02 4.73075049e-01 7.56809735e-01 9.03703505e-02\n",
            "  8.51158365e-01]\n",
            " [9.41987387e-01 2.33647615e-01 1.74734261e-02 2.69130513e-01\n",
            "  9.77504020e-01]\n",
            " [3.55685275e-01 1.50360197e-01 2.27786856e-01 6.49179056e-01\n",
            "  5.40359644e-01]\n",
            " [3.88852171e-01 2.65061067e-01 4.34087794e-01 9.86626502e-02\n",
            "  4.58723496e-01]\n",
            " [6.97039277e-01 6.84425664e-01 9.85711209e-01 4.80243992e-01\n",
            "  8.75326211e-01]\n",
            " [3.81759910e-01 3.81088865e-02 5.52054204e-01 8.13650544e-02\n",
            "  9.21009360e-01]\n",
            " [7.61335410e-01 6.50758332e-02 8.06462320e-01 5.17082869e-01\n",
            "  7.13689345e-01]\n",
            " [5.50787954e-01 5.07957129e-01 8.57189534e-01 6.56650485e-01\n",
            "  3.47618639e-01]\n",
            " [7.06158455e-01 7.97789884e-01 9.23761097e-01 6.60778087e-01\n",
            "  6.24892305e-01]\n",
            " [8.80995295e-02 4.38964908e-01 1.35248555e-02 6.89916198e-01\n",
            "  4.41111788e-01]\n",
            " [3.04206201e-01 6.74635051e-01 2.94178334e-02 4.99248889e-01\n",
            "  7.97799203e-01]\n",
            " [4.06685233e-01 7.37099816e-01 5.69494654e-01 3.39782239e-01\n",
            "  3.42853526e-01]\n",
            " [1.67205467e-01 5.51657941e-01 7.99301715e-01 5.64872423e-01\n",
            "  7.65671544e-01]\n",
            " [4.80584937e-01 8.59154945e-01 8.22139025e-01 4.64390697e-02\n",
            "  3.94075970e-03]\n",
            " [7.62289504e-01 2.21988042e-01 4.78459721e-01 5.32455351e-01\n",
            "  4.64506418e-01]\n",
            " [6.90452543e-01 6.49696247e-01 7.70728056e-01 8.85279532e-01\n",
            "  1.19475566e-04]\n",
            " [8.29134626e-01 8.21068346e-02 3.04641448e-01 4.05223245e-01\n",
            "  4.33585374e-01]\n",
            " [9.77272749e-01 7.05503401e-01 1.54760388e-01 2.68488795e-01\n",
            "  6.32941366e-01]\n",
            " [5.24104223e-01 6.19081146e-01 2.14433988e-01 1.99463670e-01\n",
            "  3.72020274e-01]\n",
            " [7.09616281e-01 5.61071785e-01 8.13280475e-01 5.31725282e-01\n",
            "  7.07478885e-02]\n",
            " [8.79905407e-02 1.68395849e-01 8.38855708e-01 4.06355875e-01\n",
            "  4.95873710e-01]\n",
            " [4.74326040e-01 2.40222666e-01 5.16016345e-01 8.12860484e-01\n",
            "  6.09893159e-01]\n",
            " [6.10560791e-01 3.68927883e-01 9.15104971e-01 5.39256654e-01\n",
            "  6.06197408e-01]\n",
            " [2.62249591e-01 9.97666022e-01 2.43098358e-01 3.82765127e-01\n",
            "  9.45822840e-01]\n",
            " [9.54020048e-01 6.56752542e-01 4.65628945e-01 9.87692357e-01\n",
            "  7.49111276e-01]\n",
            " [8.66244017e-01 5.21557064e-01 6.40217323e-01 9.30730693e-01\n",
            "  5.09273405e-01]\n",
            " [6.80670570e-01 9.43562919e-01 8.88291351e-01 8.98828645e-01\n",
            "  5.94118485e-01]\n",
            " [2.18904803e-01 7.71450615e-01 4.70151448e-01 4.16125310e-01\n",
            "  8.12383045e-01]\n",
            " [2.94657806e-01 6.20593532e-01 8.93258061e-01 8.64585647e-01\n",
            "  5.70335519e-01]\n",
            " [6.41033840e-01 2.11109804e-01 1.86349585e-01 1.66779744e-01\n",
            "  7.77952591e-01]\n",
            " [9.35382264e-01 8.03593614e-01 5.22630811e-01 3.36808459e-02\n",
            "  5.88344912e-01]\n",
            " [4.35475690e-01 9.24382760e-01 5.41520860e-01 8.95458440e-02\n",
            "  6.70553691e-02]\n",
            " [4.70487695e-01 6.83458951e-01 2.78010454e-01 3.20970682e-01\n",
            "  5.45297314e-01]\n",
            " [2.22110057e-01 2.57270340e-01 7.08128129e-01 3.47070474e-01\n",
            "  2.49000153e-01]\n",
            " [9.57109571e-01 2.93131724e-01 8.55941461e-02 3.20297659e-01\n",
            "  1.68728402e-01]\n",
            " [8.79798974e-01 9.85414801e-01 7.76321330e-01 4.37342616e-01\n",
            "  2.47856573e-01]] [[ 1.6194762  14.50138554]\n",
            " [ 2.00029609 13.11048828]\n",
            " [ 2.12250763 12.73960767]\n",
            " [ 2.5070305  11.88347225]\n",
            " [ 3.54493133  8.61538848]\n",
            " [ 2.2331338  12.36192967]\n",
            " [ 1.835667   13.52205038]\n",
            " [ 2.51668851 11.42749591]\n",
            " [ 3.03238417  9.94489026]\n",
            " [ 2.58493661 11.2818826 ]\n",
            " [ 2.50291136 11.85409005]\n",
            " [ 2.12164385 12.74169889]\n",
            " [ 2.40744113 11.97246365]\n",
            " [ 2.34932132 12.10321295]\n",
            " [ 1.67828344 14.13980333]\n",
            " [ 2.43863233 11.59857654]\n",
            " [ 1.75504973 13.77122315]\n",
            " [ 2.07157044 12.99317401]\n",
            " [ 2.63228614 10.94976264]\n",
            " [ 2.27530313 12.58130211]\n",
            " [ 2.91284033 10.27163701]\n",
            " [ 2.72595894 11.0468187 ]\n",
            " [ 3.11631917  9.57592485]\n",
            " [ 2.85634588 10.44265068]\n",
            " [ 2.61653208 11.28738074]\n",
            " [ 2.57240527 11.33560472]\n",
            " [ 2.08589738 12.79642485]\n",
            " [ 2.29301638 12.35131241]\n",
            " [ 2.44212365 11.7930842 ]\n",
            " [ 3.28245772  9.35332828]\n",
            " [ 2.71088033 11.08615103]\n",
            " [ 2.22090732 12.33076579]\n",
            " [ 1.55395953 14.53338199]\n",
            " [ 3.50472856  8.72304935]\n",
            " [ 1.58504284 14.24206214]\n",
            " [ 2.35734174 11.82842908]\n",
            " [ 1.94503596 13.4333001 ]\n",
            " [ 1.0800752  16.06082853]\n",
            " [ 2.74207492 10.7917042 ]\n",
            " [ 2.8156444  10.78596581]\n",
            " [ 3.91596701  7.56050727]\n",
            " [ 3.31238029  9.47120904]\n",
            " [ 3.11023762  9.86858504]\n",
            " [ 2.30177831 11.99810775]\n",
            " [ 2.44677099 11.53970048]\n",
            " [ 3.15701892  9.55841095]\n",
            " [ 3.17688333  9.68172923]\n",
            " [ 2.81180961 10.90529474]\n",
            " [ 2.28023301 12.59139943]\n",
            " [ 1.87011167 13.61252159]\n",
            " [ 2.28631101 12.18004329]\n",
            " [ 2.53497977 11.58032693]\n",
            " [ 3.68198229  8.55632648]\n",
            " [ 0.91136503 16.83502627]\n",
            " [ 2.47059042 11.72154116]\n",
            " [ 2.24997641 12.22625591]\n",
            " [ 3.72210873  8.0170199 ]\n",
            " [ 2.95910139 10.21447367]\n",
            " [ 3.523493    8.4926885 ]\n",
            " [ 1.98853541 12.93113347]\n",
            " [ 2.44286882 11.7445764 ]\n",
            " [ 2.70303956 11.28308105]\n",
            " [ 2.93690687 10.49173279]\n",
            " [ 2.23856248 12.2571927 ]\n",
            " [ 2.24962957 12.53679781]\n",
            " [ 2.43974296 12.21121026]\n",
            " [ 1.92337103 13.22094493]\n",
            " [ 1.64538718 14.04850844]\n",
            " [ 3.72274635  8.03177368]\n",
            " [ 1.97429741 13.40964562]\n",
            " [ 2.86364578 10.55639201]\n",
            " [ 2.92020374 10.16737532]\n",
            " [ 3.71337983  7.96206179]\n",
            " [ 1.67161728 14.18472949]\n",
            " [ 2.30530718 12.21304359]\n",
            " [ 2.39591547 11.68237182]\n",
            " [ 2.84870909 10.48166479]\n",
            " [ 2.21225874 12.79815885]\n",
            " [ 2.45969904 11.51976645]\n",
            " [ 2.99627585 10.29146811]\n",
            " [ 2.05469153 12.92044822]\n",
            " [ 2.7389667  10.99358206]\n",
            " [ 1.9291033  13.16570028]\n",
            " [ 2.68644171 11.02175214]\n",
            " [ 1.99747168 13.1609075 ]\n",
            " [ 2.65331869 10.96840205]\n",
            " [ 3.04004771  9.84439158]\n",
            " [ 2.83160194 10.83789139]\n",
            " [ 3.81320517  7.84217169]\n",
            " [ 3.4680225   8.68580771]\n",
            " [ 4.00547197  7.28166676]\n",
            " [ 2.68901522 10.94116335]\n",
            " [ 3.24343057  9.3689382 ]\n",
            " [ 1.98322556 13.19034136]\n",
            " [ 2.88363245 10.60659999]\n",
            " [ 2.05798052 13.11796019]\n",
            " [ 2.2982251  11.97323558]\n",
            " [ 1.78357915 13.66510873]\n",
            " [ 1.8248615  13.84092515]\n",
            " [ 3.32673429  9.29352764]]\n"
          ]
        }
      ],
      "source": [
        "print(final_population, final_objectives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB978rOKJvul"
      },
      "source": [
        "`a multi-objective optimization algorithm like Multi-Objective Differential Evolution (MODE) to optimize the weights of your custom neural network for feature extraction. `\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENtABf74KA8O",
        "outputId": "2840a61b-d4c1-4271-c585-f10a4f632df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 8)         208       \n",
            "                                                                 \n",
            " multiplication_layer (Mult  (None, 28, 2)             3584      \n",
            " iplicationLayer)                                                \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 2)             0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 56)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3792 (14.81 KB)\n",
            "Trainable params: 3792 (14.81 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "class MultiplicationLayer(Layer):\n",
        "    def __init__(self, num_filters_mult, L1, L2, **kwargs):\n",
        "        super(MultiplicationLayer, self).__init__(**kwargs)\n",
        "        self.num_filters_mult = num_filters_mult\n",
        "        self.L1 = L1\n",
        "        self.L2 = L2\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.n = input_shape[2]  # Get the 'n' dimension from the input shape\n",
        "        self.v = self.add_weight(name='v',\n",
        "                                 shape=(self.n, 2,self.L1 * self.L2),  # Update the shape to (n, 2, L2)\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True)\n",
        "        super(MultiplicationLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Initialize an empty list to store results for each filter\n",
        "        results = []\n",
        "\n",
        "        # Reshape v to match the desired shape\n",
        "        v_reshaped = tf.reshape(self.v, (self.n, 2, self.L1 * self.L2))\n",
        "\n",
        "        # Iterate over the multiplication filters (L2)\n",
        "        for i in range(self.L2):\n",
        "            # Iterate over the input channels (L1)\n",
        "            for j in range(self.L1):\n",
        "                # Perform matrix multiplication between input and v\n",
        "                channel_result = tf.matmul(inputs[:, :, :, j], v_reshaped[:, :, i * self.L1 + j])\n",
        "\n",
        "                # Append the channel result to the results list\n",
        "                results.append(channel_result)\n",
        "\n",
        "        # Stack the results to form the final result tensor of size [m x 2 x( L1 x L2)]\n",
        "        result = tf.stack(results, axis=-1)\n",
        "        #The responses of this layer are then added to obtain a single feature matrix of size m x 2;.\n",
        "        # Sum the responses along the last axis to obtain a single feature matrix of size m x 2\n",
        "        result = tf.reduce_sum(result, axis=-1)\n",
        "\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "# Step 1: Create MultiObjectiveFeatureExtraction model\n",
        "def create_mofe_model(input_shape, num_filters_conv, num_filters_mult, L1, L2):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(num_filters_conv, kernel_size=(5, 5), activation='relu', input_shape=input_shape, padding='same'))\n",
        "    model.add(MultiplicationLayer(num_filters_mult, L1, L2))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.add(Flatten())\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (28, 28, 1)  # Adjust the input shape as needed\n",
        "num_filters_conv = 8\n",
        "num_filters_mult = 8\n",
        "L1 = 8\n",
        "L2 = 8\n",
        "custom_nn = create_mofe_model(input_shape, num_filters_conv, num_filters_mult, L1, L2)\n",
        "print(custom_nn.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h02yYD6ERI0",
        "outputId": "6e504482-ebee-48d7-debf-b0d94f6566d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 13, 13, 8)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 11, 11, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               102656    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103904 (405.88 KB)\n",
            "Trainable params: 103904 (405.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_custom_feature_extraction_model(input_shape):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "    # Flatten the output\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense Layer for feature extraction\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (28, 28, 1)  # Adjust input shape to match your data\n",
        "custom_nn = create_custom_feature_extraction_model(input_shape)\n",
        "print(custom_nn.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hUoIrjyKMvR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa8dXebYKUYR"
      },
      "outputs": [],
      "source": [
        "def evaluate_classifier(predictions, true_labels):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbBuldszKYVl"
      },
      "outputs": [],
      "source": [
        "def calculate_inter_class_distance(y_true, y_pred):\n",
        "    num_classes = y_true.shape[1]\n",
        "    inter_class_distances = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        for j in range(i + 1, num_classes):\n",
        "            inter_class_distance_class = tf.reduce_sum(tf.abs(tf.reduce_mean(y_true[:, i], axis=0) - tf.reduce_mean(y_true[:, j], axis=0)))\n",
        "            inter_class_distances.append(inter_class_distance_class)\n",
        "\n",
        "    # Calculate inter-class distance using the new formula\n",
        "    inter_class_distance = tf.reduce_sum(inter_class_distances)\n",
        "    return inter_class_distance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5uYok248gMq"
      },
      "outputs": [],
      "source": [
        "def calculate_intra_class_variance(y_true, y_pred):\n",
        "    num_classes = y_true.shape[1]\n",
        "    intra_class_variances = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        # Calculate intra-class variance for each class and feature\n",
        "        intra_class_variance_class = tf.reduce_sum(tf.math.reduce_variance(y_true[:, i] - y_pred[:, i], axis=0))\n",
        "        intra_class_variances.append(intra_class_variance_class)\n",
        "\n",
        "    # Calculate intra-class variance using the new formula\n",
        "    intra_class_variance = tf.reduce_sum(intra_class_variances)\n",
        "    return intra_class_variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66PIImsmKe_k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7Kc5ktkixgS"
      },
      "outputs": [],
      "source": [
        "# Defining optimization problem and objectives here\n",
        "def evaluate_objectives(weights, train_images, train_labels):\n",
        "    # Create a clone custom neural network using the given weights\n",
        "    #updated_model = tf.keras.models.clone_model(custom_nn)\n",
        "    updated_model=custom_nn\n",
        "        # Extract the current weights from the model\n",
        "    current_weights = updated_model.get_weights()\n",
        "\n",
        "    # Initialize a list to store the updated weights\n",
        "    updated_weights = []\n",
        "\n",
        "    # Iterate through the layers of the model\n",
        "    for layer, layer_weights in zip(updated_model.layers, current_weights):\n",
        "        # Get the shapes of the weight tensors in the layer\n",
        "        weight_shapes = [w.shape for w in layer.get_weights()]\n",
        "\n",
        "        # Reshape the weights array according to the weight tensor shapes\n",
        "        reshaped_weights = []\n",
        "        weight_index = 0\n",
        "\n",
        "        for shape in weight_shapes:\n",
        "            num_params = np.prod(shape)\n",
        "            reshaped_weight = weights[weight_index : weight_index + num_params].reshape(shape)\n",
        "            reshaped_weights.append(reshaped_weight)\n",
        "            weight_index += num_params\n",
        "\n",
        "        # Append the reshaped weights to the updated_weights list\n",
        "        updated_weights.extend(reshaped_weights)\n",
        "\n",
        "    # Set the updated weights in the model\n",
        "    updated_model.set_weights(updated_weights)\n",
        "\n",
        "\n",
        "    # Extract features using the custom neural network\n",
        "    train_features = updated_model.predict(train_images)\n",
        "\n",
        "    # Calculate inter-class distance and intra-class variance\n",
        "    inter_class_distance= calculate_inter_class_distance(train_labels, train_features)\n",
        "    intra_class_variance= calculate_intra_class_variance(train_labels, train_features)\n",
        "\n",
        "    # Define your objectives:\n",
        "    # Objective 1: Maximize inter-class distance (Distance should be negated for minimization)\n",
        "    # Objective 2: Minimize intra-class variance\n",
        "    objective1 = -inter_class_distance\n",
        "    objective2 = intra_class_variance\n",
        "\n",
        "    # You can add more objectives if needed\n",
        "\n",
        "    return [objective1, objective2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd03u_lijbur"
      },
      "outputs": [],
      "source": [
        "# Defining optimization problem and objectives here\n",
        "def extract_feature_trained_model(weights, train_images, train_labels):\n",
        "    # Create a clone custom neural network using the given weights\n",
        "    #updated_model = tf.keras.models.clone_model(custom_nn)\n",
        "    updated_model=custom_nn\n",
        "        # Extract the current weights from the model\n",
        "    current_weights = updated_model.get_weights()\n",
        "\n",
        "    # Initialize a list to store the updated weights\n",
        "    updated_weights = []\n",
        "\n",
        "    # Iterate through the layers of the model\n",
        "    for layer, layer_weights in zip(updated_model.layers, current_weights):\n",
        "        # Get the shapes of the weight tensors in the layer\n",
        "        weight_shapes = [w.shape for w in layer.get_weights()]\n",
        "\n",
        "        # Reshape the weights array according to the weight tensor shapes\n",
        "        reshaped_weights = []\n",
        "        weight_index = 0\n",
        "\n",
        "        for shape in weight_shapes:\n",
        "            num_params = np.prod(shape)\n",
        "            reshaped_weight = weights[weight_index : weight_index + num_params].reshape(shape)\n",
        "            reshaped_weights.append(reshaped_weight)\n",
        "            weight_index += num_params\n",
        "\n",
        "        # Append the reshaped weights to the updated_weights list\n",
        "        updated_weights.extend(reshaped_weights)\n",
        "\n",
        "    # Set the updated weights in the model\n",
        "    updated_model.set_weights(updated_weights)\n",
        "\n",
        "\n",
        "    # Extract features using the custom neural network\n",
        "    train_features = updated_model.predict(train_images)\n",
        "\n",
        "\n",
        "\n",
        "    # You can add more objectives if needed\n",
        "\n",
        "    return train_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYBaJaroM-GZ"
      },
      "outputs": [],
      "source": [
        "# Initialize the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "input_shape = (28, 28, 1)  # Adjust the input shape as needed\n",
        "\n",
        "# Preprocess the dataset\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWBfF12bIafm",
        "outputId": "bbbd9bf2-657e-49fa-8d5a-e128a7d2de08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 3s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Extract features using the custom neural network\n",
        "train_features = custom_nn.predict(train_images)\n",
        "\n",
        "# Calculate inter-class distance and intra-class variance\n",
        "inter_class_distance= calculate_inter_class_distance(train_labels, train_features)\n",
        "intra_class_variance= calculate_intra_class_variance(train_labels, train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHLTZyGfIAo9",
        "outputId": "d7faf363-59ff-49f2-f60f-8c4ed12d7072"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.27326667>"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inter_class_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8x7Qj3iK_mP",
        "outputId": "a632e8a0-0243-4f85-c344-87743535d35c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9123746>"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intra_class_variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW1IFDIo7p3y"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "def initialize_population(pop_size, num_variables):\n",
        "    return np.random.rand(pop_size, num_variables)  # Randomly initialize population\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf0tyaw0eqpg",
        "outputId": "8968c89b-579b-4190-f696-997ce6f06f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranks: [0 3 1 0 2]\n",
            "Selected Population: [0, 3, 2]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def non_dominated_sort(objectives):\n",
        "    num_solutions = len(objectives)\n",
        "    domination_count = np.zeros(num_solutions, dtype=int)\n",
        "    dominated_solutions = [[] for _ in range(num_solutions)]\n",
        "    frontiers = []\n",
        "    ranks = np.zeros(num_solutions, dtype=int)\n",
        "\n",
        "    for i in range(num_solutions):\n",
        "        for j in range(i + 1, num_solutions):\n",
        "            if dominates(objectives[i], objectives[j]):\n",
        "                dominated_solutions[i].append(j)\n",
        "                domination_count[j] += 1\n",
        "            elif dominates(objectives[j], objectives[i]):\n",
        "                dominated_solutions[j].append(i)\n",
        "                domination_count[i] += 1\n",
        "\n",
        "        if domination_count[i] == 0:\n",
        "            ranks[i] = 0\n",
        "            frontiers.append(i)\n",
        "\n",
        "    current_rank = 0\n",
        "    while frontiers:\n",
        "        next_frontiers = []\n",
        "        for i in frontiers:\n",
        "            for j in dominated_solutions[i]:\n",
        "                domination_count[j] -= 1\n",
        "                if domination_count[j] == 0:\n",
        "                    ranks[j] = current_rank + 1\n",
        "                    next_frontiers.append(j)\n",
        "        current_rank += 1\n",
        "        frontiers = next_frontiers\n",
        "\n",
        "    return ranks\n",
        "\n",
        "def dominates(obj1, obj2):\n",
        "    # Returns True if obj1 dominates obj2, i.e., obj1 is better than obj2 in all objectives\n",
        "    return all(o1 <= o2 for o1, o2 in zip(obj1, obj2))\n",
        "\n",
        "def calculate_crowding_distance(objectives, front, num_objectives):\n",
        "    num_solutions = len(front)\n",
        "    crowding_distance = np.zeros(num_solutions)\n",
        "\n",
        "    for m in range(num_objectives):\n",
        "        front_sorted = np.argsort(objectives[front, m])\n",
        "        crowding_distance[front_sorted[0]] = crowding_distance[front_sorted[-1]] = np.inf\n",
        "        f_min = objectives[front[front_sorted[0]], m]\n",
        "        f_max = objectives[front[front_sorted[-1]], m]\n",
        "\n",
        "        if f_max == f_min:\n",
        "            continue\n",
        "\n",
        "        for i in range(1, num_solutions - 1):\n",
        "            crowding_distance[front_sorted[i]] += (objectives[front[front_sorted[i + 1]], m] -\n",
        "                                                   objectives[front[front_sorted[i - 1]], m]) / (f_max - f_min)\n",
        "\n",
        "    return crowding_distance\n",
        "\n",
        "def select_top_solutions(objectives, ranks, pop_size):\n",
        "    num_solutions = len(objectives)\n",
        "    num_objectives = len(objectives[0])\n",
        "\n",
        "    # Create a list of fronts, where each front contains solutions of the same rank\n",
        "    fronts = [[] for _ in range(int(np.max(ranks)) + 1)]\n",
        "    for i in range(num_solutions):\n",
        "        fronts[int(ranks[i])].append(i)\n",
        "\n",
        "    selected_population = []\n",
        "    num_selected = 0\n",
        "    current_front = 0\n",
        "\n",
        "    while num_selected < pop_size:\n",
        "        if len(fronts[current_front]) + num_selected <= pop_size:\n",
        "            # If adding the entire front doesn't exceed pop_size, add it\n",
        "            selected_population.extend(fronts[current_front])\n",
        "            num_selected += len(fronts[current_front])\n",
        "            current_front += 1\n",
        "        else:\n",
        "            # Sort the solutions in the current front based on crowding distance\n",
        "            front_objectives = np.array([objectives[i] for i in fronts[current_front]])\n",
        "            crowding_distance = calculate_crowding_distance(front_objectives, fronts[current_front], num_objectives)\n",
        "            crowding_order = np.argsort(crowding_distance)[::-1]\n",
        "            selected_population.extend([fronts[current_front][i] for i in crowding_order][:pop_size - num_selected])\n",
        "            break\n",
        "\n",
        "    return selected_population[:pop_size]  # Ensure the selected population size is exactly pop_size\n",
        "\n",
        "# Example usage:\n",
        "# Define your objectives as a list of lists, where each inner list represents objectives for a solution\n",
        "objectives = [[1, 2], [3, 4], [2, 3], [4, 1], [3, 3]]\n",
        "ranks = non_dominated_sort(objectives)\n",
        "print(\"Ranks:\", ranks)\n",
        "selected_population = select_top_solutions(objectives, ranks, 3)\n",
        "print(\"Selected Population:\", selected_population)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWoxXRzpNSM5"
      },
      "outputs": [],
      "source": [
        "# Differential Evolution Operators\n",
        "def mutation(population, F):\n",
        "    # Mutation operator\n",
        "    pop_size = len(population)  # Get the population size\n",
        "\n",
        "    indices = list(range(pop_size))\n",
        "    random.shuffle(indices)\n",
        "    donor_vectors = [population[i] for i in indices]\n",
        "\n",
        "    # Convert the population and donor_vectors to numpy arrays for element-wise operations\n",
        "    population = np.array(population)\n",
        "    donor_vectors = np.array(donor_vectors)\n",
        "\n",
        "    return list(population + F * (donor_vectors - population))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def crossover(target_vectors, trial_vectors, CR):\n",
        "    # Crossover operator\n",
        "    mask = np.random.rand(pop_size, num_variables) < CR\n",
        "    return np.where(mask, trial_vectors, target_vectors)\n",
        "\n",
        "# Multi-Objective Differential Evolution\n",
        "def multi_objective_differential_evolution(pop_size, num_variables, max_generations, F, CR, train_images, train_labels):\n",
        "    population = initialize_population(pop_size, num_variables)\n",
        "    objectives = []  # Initialize an empty list to store objectives\n",
        "\n",
        "    for generation in range(max_generations):\n",
        "        print(f\"{generation} -----------------------------\")\n",
        "        trial_population = mutation(population, F)\n",
        "        trial_population = np.clip(trial_population, 0, 1)  # Ensure solutions are within bounds\n",
        "        print(trial_population)\n",
        "\n",
        "        # Evaluate objectives for trial population\n",
        "        trial_objectives = [evaluate_objectives(weights, train_images, train_labels) for weights in trial_population]\n",
        "\n",
        "\n",
        "        # Implement non-dominated sorting and crowding distance\n",
        "        ranks = non_dominated_sort(trial_objectives)\n",
        "        top_solutions = select_top_solutions( trial_objectives, ranks, pop_size)\n",
        "\n",
        "        # Update population and objectives with the selected solutions\n",
        "        #population = top_solutions\n",
        "        population = [population[i] for i in top_solutions]\n",
        "\n",
        "        objectives = trial_objectives\n",
        "\n",
        "        print(f\"Generation {generation + 1}/{max_generations} completed.\")\n",
        "\n",
        "    return population, objectives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivhC5NdrOB0P",
        "outputId": "25188b5b-9604-47ec-84b6-dcdcd721e01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable weights: 103904\n",
            "Number of trainable weights: 103904\n",
            "0 -----------------------------\n",
            "[[0.73418722 0.59751408 0.05948286 ... 0.2847123  0.91014355 0.69047591]\n",
            " [0.09007344 0.76071731 0.47471063 ... 0.06829643 0.77406716 0.75434077]\n",
            " [0.76649592 0.39422821 0.57699122 ... 0.45475215 0.4568856  0.90251626]\n",
            " [0.76649592 0.39422821 0.57699122 ... 0.45475215 0.4568856  0.90251626]]\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "Generation 1/5 completed.\n",
            "1 -----------------------------\n",
            "[[0.09007344 0.76071731 0.47471063 ... 0.06829643 0.77406716 0.75434077]\n",
            " [0.8324886  0.45401603 0.36294784 ... 0.56720237 0.78409385 0.76637804]\n",
            " [0.8324886  0.45401603 0.36294784 ... 0.56720237 0.78409385 0.76637804]\n",
            " [0.60220187 0.47793844 0.48756961 ... 0.05981187 0.25572705 0.96275235]]\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "Generation 2/5 completed.\n",
            "2 -----------------------------\n",
            "[[0.51043171 0.53561764 0.57056173 ... 0.45899443 0.71605565 0.79831047]\n",
            " [0.34613765 0.61932788 0.48114012 ... 0.06405415 0.5148971  0.85854656]\n",
            " [0.66819454 0.53772626 0.27352623 ... 0.17226209 0.5829353  0.82661413]\n",
            " [0.8324886  0.45401603 0.36294784 ... 0.56720237 0.78409385 0.76637804]]\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "Generation 3/5 completed.\n",
            "3 -----------------------------\n",
            "[[0.34613765 0.61932788 0.48114012 ... 0.06405415 0.5148971  0.85854656]\n",
            " [0.41213033 0.6791157  0.26709674 ... 0.17650436 0.84210535 0.72240834]\n",
            " [0.66819454 0.53772626 0.27352623 ... 0.17226209 0.5829353  0.82661413]\n",
            " [0.93078998 0.31051798 0.66641283 ... 0.84969243 0.65804414 0.84228017]]\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "Generation 4/5 completed.\n",
            "4 -----------------------------\n",
            "[[0.66819454 0.53772626 0.27352623 ... 0.17226209 0.5829353  0.82661413]\n",
            " [0.09007344 0.76071731 0.47471063 ... 0.06829643 0.77406716 0.75434077]\n",
            " [0.66819454 0.53772626 0.27352623 ... 0.17226209 0.5829353  0.82661413]\n",
            " [0.93078998 0.31051798 0.66641283 ... 0.84969243 0.65804414 0.84228017]]\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "Generation 5/5 completed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calculate the number of trainable parameters (weights) in the model\n",
        "num_trainable_weights = custom_nn.count_params()\n",
        "\n",
        "print(\"Number of trainable weights:\", num_trainable_weights)\n",
        "\n",
        "# Example usage\n",
        "pop_size = 4\n",
        "num_variables = num_trainable_weights  # Use the actual number of weights in your model\n",
        "\n",
        "print(\"Number of trainable weights:\", num_variables)\n",
        "max_generations = 5\n",
        "F = 0.5  # Mutation scaling factor\n",
        "CR = 0.7  # Crossover probability\n",
        "\n",
        "# Call the multi-objective differential evolution function to optimize the weights\n",
        "final_population, final_objectives = multi_objective_differential_evolution(pop_size, num_variables, max_generations, F, CR,train_images, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr06rtL1A74j",
        "outputId": "3bd5e1d5-18b0-4051-c4e3-dd1a6cb998d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.09007344 0.76071731 0.47471063 ... 0.06829643 0.77406716 0.75434077]\n",
            " [0.60220187 0.47793844 0.48756961 ... 0.05981187 0.25572705 0.96275235]\n",
            " [0.73418722 0.59751408 0.05948286 ... 0.2847123  0.91014355 0.69047591]\n",
            " [0.93078998 0.31051798 0.66641283 ... 0.84969243 0.65804414 0.84228017]]\n"
          ]
        }
      ],
      "source": [
        "#final_trial_population = mutation(final_population, F)\n",
        "final_trial_population=np.array(final_population)\n",
        "final_trial_population = np.clip(final_trial_population, 0, 1)  # Ensure solutions are within bounds\n",
        "print(final_trial_population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOReh71H3QPr",
        "outputId": "f2ad2e47-788f-4698-eb31-a85a34aded38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n",
            "1875/1875 [==============================] - 3s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_features_list=[]\n",
        "for weights in final_trial_population:\n",
        "    updated_model = tf.keras.models.clone_model(custom_nn)\n",
        "        # Extract the current weights from the model\n",
        "    current_weights = updated_model.get_weights()\n",
        "\n",
        "    # Initialize a list to store the updated weights\n",
        "    updated_weights = []\n",
        "\n",
        "    # Iterate through the layers of the model\n",
        "    for layer, layer_weights in zip(updated_model.layers, current_weights):\n",
        "        # Get the shapes of the weight tensors in the layer\n",
        "        weight_shapes = [w.shape for w in layer.get_weights()]\n",
        "\n",
        "        # Reshape the weights array according to the weight tensor shapes\n",
        "        reshaped_weights = []\n",
        "        weight_index = 0\n",
        "\n",
        "        for shape in weight_shapes:\n",
        "            num_params = np.prod(shape)\n",
        "            reshaped_weight = weights[weight_index : weight_index + num_params].reshape(shape)\n",
        "            reshaped_weights.append(reshaped_weight)\n",
        "            weight_index += num_params\n",
        "\n",
        "        # Append the reshaped weights to the updated_weights list\n",
        "        updated_weights.extend(reshaped_weights)\n",
        "\n",
        "    # Set the updated weights in the model\n",
        "    updated_model.set_weights(updated_weights)\n",
        "\n",
        "\n",
        "    # Extract features using the custom neural network\n",
        "    train_features = updated_model.predict(train_images)\n",
        "    train_features_list.append(train_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mxSb33Ns6vm"
      },
      "outputs": [],
      "source": [
        "# Assuming you have final_population and final_objectives\n",
        "\n",
        "# Calculate the Pareto front ranks using your non-dominated sorting function\n",
        "pareto_ranks = non_dominated_sort(final_objectives)\n",
        "\n",
        "# Find the solutions that belong to the Pareto front (rank 1)\n",
        "pareto_front_indices = [i for i, rank in enumerate(pareto_ranks) if rank == 1]\n",
        "\n",
        "# Extract the weights corresponding to the Pareto front\n",
        "pareto_front_weights = [final_trial_population[i] for i in pareto_front_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd_U7WZ7_ep8",
        "outputId": "48333b6e-e441-4a52-8750-2c60f8f23919"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0.09667228, 0.9518865 , 0.47721492, ..., 0.56211838, 0.96088953,\n",
              "        0.38476003])]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pareto_front_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "S0espxMK3s6N",
        "outputId": "07b2221f-858f-498d-a021-8b58905dc3d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-8f2166f52682>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mreshaped_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpareto_front_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mweight_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mreshaped_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mweight_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
          ]
        }
      ],
      "source": [
        "#updated_model = tf.keras.models.clone_model(custom_nn)\n",
        "        # Extract the current weights from the model\n",
        "updated_model=custom_nn\n",
        "current_weights = updated_model.get_weights()\n",
        "\n",
        "    # Initialize a list to store the updated weights\n",
        "updated_weights = []\n",
        "\n",
        "    # Iterate through the layers of the model\n",
        "for layer, layer_weights in zip(updated_model.layers, current_weights):\n",
        "        # Get the shapes of the weight tensors in the layer\n",
        "    weight_shapes = [w.shape for w in layer.get_weights()]\n",
        "\n",
        "        # Reshape the weights array according to the weight tensor shapes\n",
        "    reshaped_weights = []\n",
        "    weight_index = 0\n",
        "\n",
        "    for shape in weight_shapes:\n",
        "        num_params = np.prod(shape)\n",
        "        reshaped_weight = pareto_front_weights[weight_index : weight_index + num_params].reshape(shape)\n",
        "        reshaped_weights.append(reshaped_weight)\n",
        "        weight_index += num_params\n",
        "\n",
        "        # Append the reshaped weights to the updated_weights list\n",
        "    updated_weights.extend(reshaped_weights)\n",
        "\n",
        "    # Set the updated weights in the model\n",
        "updated_model.set_weights(updated_weights)\n",
        "\n",
        "\n",
        "    # Extract features using the custom neural network\n",
        "train_features = updated_model.predict(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV55HMf7DTEa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCw_suqMBsK2",
        "outputId": "5b071607-7ef8-4a41-989a-9bb4d166cdb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7777119. , 7997702. , 7220512.5, 8006653.5, 7720430. , 8073538. ,\n",
              "       8144563. , 8232164.5, 8176256.5, 7543603. , 7255193. , 7627174.5,\n",
              "       7575721. , 7933093.5, 8163691. , 7251688.5, 7729919.5, 7674822. ,\n",
              "       8309133. , 7207106. , 8244651.5, 7434572.5, 8138734. , 7924461. ,\n",
              "       7854826.5, 7732032.5, 7712145.5, 7213845.5, 7469035.5, 8298029. ,\n",
              "       7456403.5, 7588150.5, 7678270. , 7724569. , 7830335.5, 7269918. ,\n",
              "       7693473. , 7325042.5, 7811394.5, 7426039.5, 7052945. , 7790045.5,\n",
              "       7715797. , 7224350.5, 7612287.5, 7595324.5, 7418945.5, 6744634. ,\n",
              "       7949279. , 8170516.5, 7611815.5, 7632948.5, 7532130. , 8049998.5,\n",
              "       7654637.5, 7970362.5, 7516620. , 8314517.5, 8154578.5, 7820690.5,\n",
              "       8052119. , 7298562. , 7680664. , 7988878.5, 8517596. , 7800164. ,\n",
              "       7514580.5, 6768123.5, 7872916. , 7628923. , 8124736. , 7865111. ,\n",
              "       7616682. , 8002407. , 7398432.5, 8018936. , 7831197. , 7901632.5,\n",
              "       8138092.5, 6970833.5, 7666737. , 7582867. , 7550795. , 6918979.5,\n",
              "       7627980. , 7245180.5, 7138292. , 7492846.5, 7366340.5, 7727495. ,\n",
              "       7367236. , 7279211.5, 7249299.5, 8241704. , 8120851.5, 7392291.5,\n",
              "       7894375.5, 6980791. , 7403673. , 7899268. , 7209842.5, 7837756. ,\n",
              "       6808673. , 7031139.5, 7588841. , 7790348. , 7142373.5, 7796252. ,\n",
              "       7549299.5, 7913868. , 7298111. , 7289999.5, 7768459.5, 8576072. ,\n",
              "       7357364. , 8269126. , 8443111. , 7748814. , 7655660.5, 7276112. ,\n",
              "       7491164.5, 7740214.5, 7863398. , 8049557. , 8492131. , 7573693. ,\n",
              "       7770539. , 8087598.5, 7851465. , 7818864.5, 7345406. , 8029518. ,\n",
              "       7949842. , 8633859. , 8351773. , 7677551. , 7685588.5, 7657281. ,\n",
              "       7577206.5, 7046773.5, 8048629. , 7953146.5, 7671274.5, 7371488. ,\n",
              "       7283071. , 7913362.5, 7834148. , 7297263.5, 8015204.5, 7713591. ,\n",
              "       7174753.5, 7287987.5, 7734597. , 7127295.5, 8136092. , 7385203. ,\n",
              "       7347895.5, 7557968. , 8036904. , 7739126.5, 7795858.5, 7629027. ,\n",
              "       7841145.5, 7791211.5, 7220368. , 7968383. , 7212786.5, 7584930. ,\n",
              "       6954567. , 6675708.5, 7335883.5, 7322215.5, 7666136.5, 7613491.5,\n",
              "       7480065.5, 7371472. , 7834650.5, 7055308. , 7631336. , 7963979. ,\n",
              "       7439597. , 7768937. , 7677205. , 7201947.5, 7580894. , 8110394.5,\n",
              "       6712307.5, 7561177.5, 7382613.5, 7691602. , 7527582. , 7295997.5,\n",
              "       7410372. , 7995823.5, 7286513. , 8033267.5, 7003050. , 7904193.5,\n",
              "       7909376. , 7310582. , 7177447. , 7997236.5, 7253683.5, 7799825. ,\n",
              "       7459864. , 7415648. , 8063031.5, 7143090. , 7269711. , 7600097. ,\n",
              "       7970297.5, 7222295.5, 6931851.5, 7166089.5, 7503325.5, 7686515. ,\n",
              "       7808321.5, 7956455. , 7841493.5, 7455611.5, 8666677. , 7543586. ,\n",
              "       7381298. , 7708470.5, 7238528. , 7251741. , 7392862. , 7430925. ,\n",
              "       7492152. , 7473628.5, 7709668.5, 8605941. , 7915376.5, 8085793.5,\n",
              "       7816589. , 7321056.5, 8015402.5, 7386908. , 7638163. , 7874848. ,\n",
              "       7761353. , 7475148. , 7827434. , 7704554. , 7468172. , 8047117.5,\n",
              "       8571099. , 6766843. , 7154877. , 7677932. , 7115181.5, 7587751. ,\n",
              "       7452242.5, 6910659.5, 7961965.5, 7787591.5], dtype=float32)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED7KwINfx280",
        "outputId": "f72f67f1-7041-473b-9bd5-aff8590a7d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy (train): 0.87\n",
            "Classification Accuracy (train): 0.87\n",
            "Classification Accuracy (train): 0.87\n",
            "Classification Accuracy (train): 0.87\n"
          ]
        }
      ],
      "source": [
        "for features in train_features_list:\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "    classifier.fit(features, train_labels)\n",
        "\n",
        "    # Evaluate the accuracy of the classifier on the training data\n",
        "    predicted_labels = classifier.predict(features)\n",
        "    accuracy = accuracy_score(train_labels, predicted_labels)\n",
        "    print(f\"Classification Accuracy (train): {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEQ4N4D191MY",
        "outputId": "461a49e3-856f-49b3-d5bd-61e8deb88fd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features[200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqvG2DR9ywTx"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tZpHqMvy7u6",
        "outputId": "d4f21c40-f35b-4599-c4b1-851c24b5b994"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 3792)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JWuUX31yh6V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcj-a1Y7s9jy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG0eb5ttPIY3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}